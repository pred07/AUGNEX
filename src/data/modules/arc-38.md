# Ethics of AI Defense

## 1. Orientation

### What this module covers
This module covers **Autonomous Defense**. When the machine fights back.

### Fit in the Learning Path
Speed demands AI. But AI lacks morality.

### Learning Objectives
By the end of this module, you should understand:
*   **Bias in Algorithms**.
*   **Autonomous Action**.
*   **The "Kill Switch"**.

---

## 2. Core Content

### The Bias
*   AI learns from specific datasets. If the data is biased, the security decisions will be biased.
*   *Example*: Fraud detection blocking legitimate users from specific regions unfairly.

### Autonomous Response
*   AI detects an intrusion.
*   AI decides to "Isolate the Host".
*   *Scenario*: The host was a critical life-support system in a hospital.
*   *Risk*: Automated measures causing physical harm.

---

## 3. Guided Practice

### The Rules of Engagement
**Policy**: What can the AI do alone?
1.  **Block IP**: Yes.
2.  **Lock Account**: Yes.
3.  **Shutdown Server**: NO. (Human Approval Required).

**Exercise**: Define the "Human in the Loop" boundary for your org.

---

## 4. Reflection Check

1.  **Explainability**: "Computer says no" isn't enough. You need Explainable AI (XAI). Why was it blocked?
2.  **Accountability**: If the AI breaks it, *you* are responsible. You cannot blame the algorithm.
3.  **Arms Race**: Attackers will use AI. Defenders must use AI. The OODA loop moves to milliseconds.

---

## 5. Completion Criteria

This module is complete when:
1.  You understand **Algorithmic Bias**.
2.  You define **Autonomous Guardrails**.
3.  You maintain **Human Accountability**.
