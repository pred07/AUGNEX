# Signal vs Noise

## 1. Orientation

### What this module covers
This module covers the fundamental challenge of security operations—separating meaningful signals from overwhelming noise. Effective detection isn't about finding everything; it's about finding the right things.

### Fit in the Learning Path
SOC teams drown in data. Terabytes of logs generate thousands of alerts. Without proper filtering and prioritization, critical threats hide in the noise and analysts burn out. This module teaches the science of signal extraction.

### Learning Objectives
By the end of this module, you will:
*   Calculate and improve Signal-to-Noise Ratio (SNR)
*   Develop effective filtering strategies
*   Balance detection coverage with alert fatigue
*   Recognize normalization of deviance

---

## 2. Core Content

### Mental Model: The Needle and the Haystack

**How professionals think about this:**
Security isn't about building a bigger haystack detector—it's about making the needle easier to find. Every piece of noise removed makes the signal clearer. The goal is relentless noise reduction without creating blind spots.

```
SIGNAL vs NOISE CONCEPT:

THE PROBLEM:
┌─────────────────────────────────────────────────────────────────────┐
│                                                                     │
│  RAW LOGS: 10 Terabytes / day                                      │
│  ALERTS:   10,000 / day                                            │
│  ANALYSTS: 5 people                                                │
│  CAPACITY: 50 investigations / day                                 │
│                                                                     │
│  RESULT:   9,950 alerts IGNORED                                    │
│            Attackers hide in that noise                            │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘

THE SOLUTION:
┌─────────────────────────────────────────────────────────────────────┐
│                                                                     │
│  RAW LOGS:      10 Terabytes / day                                 │
│  ↓ Parse/Normalize                                                 │
│  EVENTS:        500 Million events                                 │
│  ↓ Filter Known-Good                                               │
│  SUSPICIOUS:    50,000 events                                      │
│  ↓ Detection Rules                                                 │
│  ALERTS:        100 / day                                          │
│  ↓ Prioritization                                                  │
│  INVESTIGATIONS: 50 / high priority                                │
│                                                                     │
│  RESULT:   Every alert investigated                                │
│            Attackers cannot hide                                   │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### Signal-to-Noise Ratio (SNR)

**Measuring detection quality:**

```
SNR CALCULATION:

                True Positives              
SNR = ──────────────────────────────────────
       True Positives + False Positives    

EXAMPLE:
Alert rule triggers 100 times/day
5 are real attacks (True Positives)
95 are false positives (Noise)

SNR = 5 / (5 + 95) = 0.05 = 5%

THIS IS BAD. Analyst ignores this alert.

GOAL SNR BY SEVERITY:
─────────────────────────────
Critical:  >50% (1 in 2 is real)
High:      >25% (1 in 4 is real)
Medium:    >10% (1 in 10 is real)
Low:       >5% (informational)

SNR IMPROVEMENT STRATEGIES:
─────────────────────────────
1. Add conditions (more specific)
2. Exclude known-good sources
3. Add threat intel enrichment
4. Increase threshold
5. Add time window constraints
```

### Noise Categories

**Understanding where noise comes from:**

| Source | Example | Solution |
|--------|---------|----------|
| **Legitimate tools** | Vulnerability scanner triggers IDS | Whitelist scanner IP in rule |
| **Admin activity** | Sysadmin runs PowerShell scripts | Windows baseline, admin tagging |
| **Scheduled jobs** | Backup script accesses many files | Time-based exception |
| **Monitoring itself** | SIEM queries trigger alerts | Exclude monitoring IPs |
| **Misconfigurations** | Wrong threshold captures normal | Tune based on baseline |
| **Over-broad rules** | `cmd.exe` execution (too common) | Add parent process context |

### Filtering Strategies

**Reducing noise systematically:**

```
FILTERING APPROACHES:

1. EXCLUSION (Whitelisting)
   ─────────────────────────────
   "Ignore X from the rule"
   
   Original: Alert on PowerShell.exe
   Filtered: Alert on PowerShell.exe 
             WHERE User NOT IN (known_admins)
   
   Risk: Attacker compromises whitelisted source

2. AGGREGATION
   ─────────────────────────────
   "Alert only if many occurrences"
   
   Original: Alert on failed login
   Filtered: Alert on failed login 
             WHERE count > 10 IN 5 minutes
   
   Risk: Slow attacks bypass threshold

3. CORRELATION
   ─────────────────────────────
   "Alert only with supporting evidence"
   
   Original: Alert on outbound connection
   Filtered: Alert on outbound connection 
             WHERE followed by data transfer > 100MB
   
   Risk: Misses exfiltration below threshold

4. ENRICHMENT-BASED
   ─────────────────────────────
   "Filter based on context"
   
   Original: Alert on external IP connection
   Filtered: Alert on external IP 
             WHERE GeoIP = "high risk country"
             AND reputation = "unknown"
   
   Risk: Relies on quality of enrichment data

5. TIME-BASED
   ─────────────────────────────
   "Ignore during expected windows"
   
   Original: Alert on backup operations
   Filtered: Alert on backup operations
             WHERE NOT(time BETWEEN 02:00-04:00)
   
   Risk: Attacker times attacks during window
```

### Normalization of Deviance

**The danger of ignored alerts:**

```
NORMALIZATION OF DEVIANCE:

CYCLE OF FAILURE:
─────────────────────────────
1. New alert rule deployed
2. Alert fires frequently
3. Most alerts are false positives
4. Analyst stops investigating that alert
5. Alert becomes "normal" (ignored)
6. Real attack triggers same alert
7. Alert ignored → Breach

HISTORICAL EXAMPLES:
─────────────────────────────
Target Breach:   FireEye alerts ignored
Equifax Breach:  Certificate expiry warnings ignored
Yahoo Breach:    Anomaly alerts normalized

PREVENTION:
─────────────────────────────
1. Metrics: Track investigation rate per alert
2. Accountability: Justify not investigating
3. Tuning: Fix noisy rules (don't just ignore)
4. Rotation: Fresh eyes catch normalized deviance
5. Automation: Auto-enrich to help triage
```

### The Tuning Lifecycle

**Continuous improvement:**

```
ALERT TUNING PROCESS:

┌─────────────────────────────────────────────────────────────────────┐
│                                                                     │
│  1. DEPLOY RULE                                                    │
│     └─► New detection goes live                                    │
│                                                                     │
│  2. OBSERVE (1-2 weeks)                                            │
│     └─► Collect data: volume, TP/FP ratio                          │
│                                                                     │
│  3. ANALYZE                                                        │
│     └─► What patterns are in the false positives?                  │
│     └─► Common sources, times, users?                              │
│                                                                     │
│  4. TUNE                                                           │
│     └─► Add exclusions for documented known-good                   │
│     └─► Increase specificity                                       │
│     └─► Adjust thresholds                                          │
│                                                                     │
│  5. VALIDATE                                                       │
│     └─► Test against known attacks (purple team)                   │
│     └─► Confirm true positives still detected                      │
│                                                                     │
│  6. DOCUMENT                                                       │
│     └─► Why each exclusion exists                                  │
│     └─► When to review (quarterly)                                 │
│                                                                     │
│  7. REPEAT                                                         │
│     └─► Environment changes, tune again                            │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### Metrics That Matter

**Measuring SOC effectiveness:**

| Metric | Formula | Target |
|--------|---------|--------|
| **SNR** | TP / (TP + FP) | >25% for high |
| **Mean Time to Detect** | Time from attack to alert | <1 hour |
| **Mean Time to Respond** | Time from alert to action | <4 hours |
| **Alert Volume** | Alerts per analyst per day | <50 |
| **Investigation Rate** | Alerts investigated / total | >90% |
| **Tune Rate** | Rules tuned per month | Continuous |

---

## 3. Guided Practice

### Exercise 1: SNR Calculation

Alert: "Port Scan Detected"
- Fires 1000 times/week
- Investigation reveals:
  - 950 from Vulnerability Scanner
  - 45 from IT admin testing
  - 5 from unknown sources

1. Current SNR: ___
2. After excluding scanner: ___
3. Recommended action: ___

### Exercise 2: Noise Categorization

For each alert, categorize the noise source:

| Alert | Volume | Root Cause | Solution |
|-------|--------|------------|----------|
| PowerShell execution | 500/day | ___ | ___ |
| Failed login | 10000/day | ___ | ___ |
| Outbound DNS | 1000/day | ___ | ___ |

### Exercise 3: Tuning Decision

Alert: "Unusual process spawned by Word"
- Volume: 20/day
- True positives: 0 this month
- False positives: All from macro-enabled templates

Should you disable the rule? Justify:
___

---

## 4. Reflection Check

### Signal Understanding
1. Alert never fires. Is the rule useless or is the environment secure?

2. SNR is 100% (all true positives). Could this still be a problem?

3. Analyst ignores alert for 6 months. Should rule be disabled?

### Operational Thinking
1. Scanner IP changes. What breaks?

2. New admin joins team. Impact on whitelists?

3. Alert volume drops to zero after tuning. Concern?

---

## 5. Key Misconceptions

**MYTH: "More alerts = better security"**
REALITY: Too many alerts leads to ignored alerts. Quality over quantity.

**MYTH: "Whitelisting is always safe"**
REALITY: Every whitelist is a potential blind spot. Document and review regularly.

**MYTH: "Low SNR rules should be disabled"**
REALITY: Tune first. The detection logic may be good; the filtering may be bad.

**MYTH: "Automation solves alert fatigue"**
REALITY: Automation helps triage but doesn't fix bad rules. Tune the source.

**MYTH: "If we didn't detect it, it didn't happen"**
REALITY: Detection has gaps. Absence of alerts ≠ absence of attacks.

---

## 6. Completion Criteria

This module is complete when you can:

1. **Calculate** Signal-to-Noise Ratio
2. **Categorize** noise sources
3. **Apply** filtering strategies appropriately
4. **Recognize** normalization of deviance
5. **Tune** rules without creating blind spots

---

## 7. Further Depth (Optional)

*   **Practice:** Audit your current alert rules for SNR
*   **Metrics:** Build SOC dashboard for alert efficiency
*   **Research:** Detection engineering best practices
*   **Tool:** Implement alert feedback loop in SIEM
