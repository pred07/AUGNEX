# Rule-Based vs Behavioral Detection

## 1. Orientation

### What this module covers
This module compares static rule-based detection with dynamic behavioral detection. Understanding the strengths and limitations of each approach is essential for building comprehensive detection coverage.

### Fit in the Learning Path
Static rules catch known threats quickly. Behavioral detection catches unknown threats but with more complexity. Mature security programs use both strategically—this module teaches you when to apply each.

### Learning Objectives
By the end of this module, you will:
*   Differentiate IOCs from IOAs
*   Understand behavioral detection principles
*   Apply UEBA concepts
*   Build layered detection strategies

---

## 2. Core Content

### Mental Model: The Known vs The Unknown

**How professionals think about this:**
Rules catch what we know is bad. Behavior catches what looks wrong. Rules are signatures of past attacks. Behavior is patterns of current deviations. You need both—rules for speed, behavior for coverage.

```
DETECTION SPECTRUM:

                    STATIC                              DYNAMIC
                    (Rules)                             (Behavior)
    ←─────────────────────────────────────────────────────────────→
    
    Hash Match   |   IP Block   |   Signature   |   Anomaly   |   UEBA
    
    CHARACTERISTICS:
    ─────────────────────────────────────────────────────────────────
    Fast         |                               |            Slow
    Exact        |                               |            Fuzzy
    Low FP       |                               |            High FP
    Known only   |                               |            Unknown capable
    Easy bypass  |                               |            Hard bypass
    Simple       |                               |            Complex
    
    PYRAMID OF PAIN MAPPING:
    ─────────────────────────────────────────────────────────────────
    Hash         →     Bottom (trivial to change)
    IP/Domain    →     
    Artifact     →     
    Tool         →     
    TTP          →     Top (behavioral, hard to change)
```

### Indicators of Compromise (IOCs)

**Static, known-bad signatures:**

```
IOC TYPES:

FILE-BASED:
─────────────────────────────
Hash (MD5, SHA1, SHA256)
File name patterns
File path locations
File size ranges
YARA signatures

NETWORK-BASED:
─────────────────────────────
IP addresses
Domain names
URLs
SSL certificate hashes
JA3/JA3S fingerprints

ARTIFACT-BASED:
─────────────────────────────
Registry keys
Mutex names
Scheduled task names
Process names

IOC LIFECYCLE:
─────────────────────────────
1. Attack discovered
2. IOCs extracted
3. IOCs shared (feeds, reports)
4. Rules created
5. Future attacks detected
6. Attacker changes IOCs
7. IOCs become stale

PROBLEM:
Day 0: Attack uses malware.exe (hash: abc123)
Day 1: IOC shared, rule created
Day 2: Attacker recompiles (hash: def456)
Day 3: Rule no longer detects

IOC HALF-LIFE: Often measured in hours
```

### Indicators of Attack (IOAs)

**Behavioral patterns:**

```
IOA CONCEPTS:

IOAs focus on BEHAVIOR, not ARTIFACTS:
─────────────────────────────
"What does the attacker DO?"
Not "What file did they use?"

EXAMPLES:

Instead of: Hash of Mimikatz
IOA: Process accessing LSASS memory

Instead of: C2 domain
IOA: Beaconing pattern (regular interval, same destination)

Instead of: Specific exploit
IOA: Child process of Office accessing network

MITRE ATT&CK AS IOAs:
─────────────────────────────
T1003: Credential Dumping (behavior: accessing SAM/LSASS)
T1059: Command Line Interface (behavior: scripting from unusual parent)
T1086: PowerShell (behavior: encoded commands, download cradle)
T1055: Process Injection (behavior: remote thread creation)

IOA ADVANTAGES:
─────────────────────────────
- Detects new variants
- Attacker must change technique, not just tool
- Maps to MITRE ATT&CK framework
- More stable over time
```

### Behavioral Detection Methods

**Types of behavioral analysis:**

```
BEHAVIORAL DETECTION APPROACHES:

1. BASELINE DEVIATION
   ─────────────────────────────
   Establish "normal" for entity
   Alert when deviation exceeds threshold
   
   Example:
   Normal: User logs in 9 AM-6 PM weekdays
   Alert: Login at 3 AM Saturday from new country

2. PEER COMPARISON
   ─────────────────────────────
   Compare entity to similar entities
   Alert on significant differences
   
   Example:
   Normal: Marketing downloads 5 files/day
   User: Downloads 500 files/day
   Alert: User deviates from peer group

3. IMPOSSIBLE TRAVEL
   ─────────────────────────────
   Detect physically impossible scenarios
   
   Example:
   10:00 AM: Login from New York
   10:15 AM: Login from Tokyo
   Alert: Cannot travel 6,800 miles in 15 minutes

4. FIRST-TIME EVENTS
   ─────────────────────────────
   Track entity's history
   Alert on never-before-seen actions
   
   Example:
   User: First time running PowerShell
   User: First connection to this country
   Alert: New behavior for this entity

5. SEQUENCE ANOMALIES
   ─────────────────────────────
   Detect unusual order of events
   
   Example:
   Normal: Login → Email → Documents
   Attack: Login → Admin Tools → Data Export → Encryption
   Alert: Unusual action sequence
```

### User and Entity Behavior Analytics (UEBA)

**Advanced behavioral detection:**

```
UEBA ARCHITECTURE:

DATA SOURCES:
─────────────────────────────
Authentication logs (AD, VPN, apps)
Network traffic (proxy, firewall)
Email activity (send, receive, attachments)
File access (DLP, file servers)
Endpoint activity (EDR, process logs)

ENTITY MODELING:
─────────────────────────────
User Profiles:
- Work hours
- Typical locations
- Normal applications
- Data access patterns
- Communication patterns

Asset Profiles:
- Normal services
- Expected connections
- Baseline resource usage
- Authorized users

RISK SCORING:
─────────────────────────────
Each anomaly adds points to risk score
Multiple small anomalies = investigation
Single major anomaly = alert

Example:
Monday 10 AM, usual office + 0 points
Monday 3 AM, from home + 10 points
Monday 3 AM, from Russia + 50 points
Monday 3 AM, Russia, downloads 1GB + 100 points

Threshold: 75 points = ALERT

UEBA DETECTION SCENARIOS:
─────────────────────────────
- Compromised credentials (attacker behavior differs)
- Insider threat (unusual access patterns)
- Privilege abuse (accessing unauthorized data)
- Data exfiltration (unusual data movement)
- Account takeover (behavior shift after compromise)
```

### Comparing Approaches

**Strategic application:**

| Aspect | Rule-Based | Behavioral |
|--------|------------|------------|
| **Speed** | Milliseconds | Seconds to minutes |
| **Accuracy** | High (if matched) | Variable (baseline quality) |
| **False Positives** | Low | Higher |
| **New Threats** | No | Yes |
| **Maintenance** | Signature updates | Model training |
| **Evasion** | Change IOC | Change behavior (harder) |
| **Cost** | Low | High (compute, storage) |
| **Explainability** | "Matched rule X" | "Scored 85 due to..." |

### Layered Detection Strategy

**Combining approaches:**

```
DEFENSE IN DEPTH FOR DETECTION:

LAYER 1: KNOWN BAD (Fast, cheap)
─────────────────────────────
Block threat intel feeds
Hash matching
Signature detection
→ Catches commodity attacks

LAYER 2: RULES (Specific, maintained)
─────────────────────────────
Custom detection rules
ATT&CK-based detections
Application-specific rules
→ Catches targeted attacks

LAYER 3: BEHAVIOR (Broad, expensive)
─────────────────────────────
UEBA scoring
Anomaly detection
ML-based classification
→ Catches novel attacks

LAYER 4: HUNTING (Manual, expert)
─────────────────────────────
Hypothesis-driven searching
Threat intelligence application
Pattern discovery
→ Finds what automation misses

COVERAGE EXAMPLE - RANSOMWARE:
─────────────────────────────
Layer 1: Block known ransomware hashes
Layer 2: Detect mass file modification patterns
Layer 3: Alert on user accessing unusual file shares
Layer 4: Hunt for pre-ransomware behaviors (recon, cred theft)
```

### Machine Learning in Detection

**When ML helps:**

```
ML FOR SECURITY DETECTION:

GOOD FIT:
─────────────────────────────
- Pattern too complex for rules
- Many features to analyze
- Good training data available
- False positives acceptable

EXAMPLES:
- Malware classification (file features)
- DGA domain detection (linguistic patterns)
- Network anomaly detection (traffic patterns)
- User risk scoring (behavior aggregation)

CAUTION:
─────────────────────────────
- ML is not magic
- Requires quality training data
- Can be evaded by adversarial input
- "Black box" problem (explainability)
- High compute cost
- Maintenance burden (model drift)

HYBRID APPROACH:
─────────────────────────────
ML for: Scoring, prioritization, triage assistance
Rules for: High-confidence, well-understood threats
Humans for: Final decisions, investigation, hunting
```

---

## 3. Guided Practice

### Exercise 1: IOC vs IOA

For each threat, write an IOC rule AND an IOA rule:

**Threat: Cobalt Strike beacon**

IOC rule:
```
___
```

IOA rule:
```
___
```

Which is more resilient?

### Exercise 2: Behavioral Detection Design

Design behavioral detection for "Insider data theft":

1. Baseline what?
2. Alert on what deviation?
3. What data sources needed?
4. Potential false positives?

### Exercise 3: Layered Defense

For each attack stage, which detection layer?

| Stage | Primary Layer | Why |
|-------|---------------|-----|
| Initial phishing | ___ | ___ |
| Credential theft | ___ | ___ |
| Data exfiltration | ___ | ___ |
| Known ransomware | ___ | ___ |

---

## 4. Reflection Check

### Detection Understanding
1. IOC rule catches attack. Is it sufficient?

2. UEBA scores user at 70 (threshold 75). Safe?

3. ML model says "95% malicious". What now?

### Strategic Thinking
1. New zero-day announced. What layer helps?

2. Insider threat suspected. Best detection approach?

3. Alert fatigue from behavioral alerts. Solution?

---

## 5. Key Misconceptions

**MYTH: "ML/AI will replace rule-based detection"**
REALITY: Each has strengths. Rules for known threats, ML for patterns. Both needed.

**MYTH: "Behavioral detection catches everything"**
REALITY: Behavioral detection catches what deviates. Stealthy attacks that mimic normal behavior evade.

**MYTH: "IOCs are useless because they're easily changed"**
REALITY: IOCs catch commodity attacks. Most attackers don't customize.

**MYTH: "UEBA eliminates false positives"**
REALITY: UEBA trades rule FPs for anomaly FPs. Legitimate unusual behavior triggers alerts.

**MYTH: "More data sources = better behavioral detection"**
REALITY: Quality over quantity. Garbage in = garbage out. Noisy data hurts baselines.

---

## 6. Completion Criteria

This module is complete when you can:

1. **Contrast** IOCs with IOAs
2. **Design** behavioral detection strategies
3. **Apply** UEBA principles
4. **Recommend** when to use each approach
5. **Build** layered detection coverage

---

## 7. Further Depth (Optional)

*   **Practice:** Build both rule and behavioral detection for same attack
*   **Tool:** Explore open-source UEBA solutions
*   **Methodology:** Microsoft's Detection Maturity Model
*   **Research:** Academic papers on adversarial ML in security
