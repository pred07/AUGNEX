# Web Application Attack Surface Mapping

## 1. Orientation

### What this module covers
This module is "Recon for Web Apps". Before attacking, you need to find every page, every API endpoint, and every hidden debug folder.

### Fit in the Learning Path
You can't inject SQL into a page you haven't found. This phase maximizes your chances of finding a forgotten, vulnerable function.

### Learning Objectives
By the end of this module, you should understand:
*   **Spidering / Crawling**.
*   **Hidden Content Discovery**.
*   **API Documentation Recon**.

---

## 2. Core Content

### Spidering (Crawling)
A bot visits the homepage, follows every link, follows every link on those pages... building a map.
*   **Active**: Burp Suite Spider, OWASP ZAP.
*   **Passive**: Wayback Machine (What pages existed last year?).

### Brute Force Discovery (Fuzzing)
The spider only finds linked pages. What about unlinked ones?
*   Tool: `gobuster`, `dirb`.
*   Dictionary: `common.txt` (`/admin`, `/login`, `/backup`, `/test`).
*   Action: Try `site.com/word`. If 200 OK -> Found. If 404 -> Missing.

---

## 3. Guided Practice

### Mapping Methodology
**Step 1: Click Everything**
Manually browse the site through a Proxy (Burp). Click every button. Fill every form.

**Step 2: Check `robots.txt`**
Often lists sensitive folders the admin doesn't want Google to see (`/admin-panel`).

**Step 3: Check `sitemap.xml`**
A map provided by the developers for SEO.

**Step 4: Check JavaScript**
View Source. Search for "api/", "v1/", "http". Developers often hardcode API endpoints in the frontend JS bundle.

---

## 4. Reflection Check

1.  **Efficiency**: Why use a wordlist? Why not try `aaa`, `aab`, `aac`? (Mathematical impossibility. A dictionary checks the most likely 10,000 folders in minutes).
2.  **Noise**: Does `gobuster` generate noise? (Yes. Thousands of 404 errors in the server logs. Very detectable).
3.  **Context**: You find `/backup.sql.zip`. What is this? (The Holy Grail. The entire database dump).

---

## 5. Completion Criteria

This module is complete when:
1.  You understand the difference between Spidering (Links) and Brute-Forcing (Guessed paths).
2.  You check `robots.txt` on every target.
3.  You know to look inside `.js` files for hidden endpoints.
