# Web Application Attack Surface Mapping

## 1. Orientation

### What this module covers
This module covers systematic web application reconnaissance—discovering every page, endpoint, API, and hidden functionality. Before you can exploit a vulnerability, you must find where it lives. Attack surface mapping maximizes your coverage and chance of finding forgotten, vulnerable functionality.

### Fit in the Learning Path
You can't inject SQL into a page you haven't found. Web application testing starts with comprehensive mapping—the quality of your attack surface map directly correlates with testing success.

### Learning Objectives
By the end of this module, you will:
*   Apply multiple discovery techniques systematically
*   Find hidden content and API endpoints
*   Use tools for automated discovery
*   Build comprehensive application maps

---

## 2. Core Content

### Mental Model: The Attack Surface Iceberg

**How professionals think about this:**
What users see is the tip of the iceberg. Hidden admin panels, legacy endpoints, debug functions, API routes, and backup files represent the vast underwater portion—often the most vulnerable.

```
WEB APPLICATION ATTACK SURFACE:

┌─────────────────────────────────────────────────────────────────────┐
│                                                                     │
│    VISIBLE SURFACE (What users see)                                 │
│    ───────────────────────────────                                  │
│    /                     Main page                                  │
│    /login                Auth page                                  │
│    /products             Product catalog                            │
│    /about                Company info                               │
│                                                                     │
│  ═══════════════════════════════════════════════════════════════   │
│                                                                     │
│    HIDDEN SURFACE (What you need to find)                           │
│    ──────────────────────────────────────                           │
│    /admin                Admin panel                                │
│    /api/v1/              API endpoints                              │
│    /backup/              Backup files                               │
│    /debug/               Debug functions                            │
│    /test/                Test pages                                 │
│    /old/                 Legacy code                                │
│    /.git/                Source code!                               │
│    /config.php.bak       Config backups                             │
│    /swagger.json         API documentation                          │
│    /phpinfo.php          Server info                                │
│    /wp-admin/            CMS admin                                  │
│    /actuator/            Spring Boot debug                          │
│    /.env                 Environment secrets                        │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### Discovery Methods

**Technique comparison:**

| Method | Finds | Noise Level | Coverage |
|--------|-------|-------------|----------|
| **Manual browsing** | Linked content | None | Low |
| **Spidering/crawling** | All linked content | Low | Medium |
| **Brute forcing** | Unlinked content | High | High |
| **JavaScript analysis** | Hidden API endpoints | None | Medium |
| **Historical data** | Removed content | None | Varies |

### Spidering and Crawling

**How crawlers work:**

```
SPIDERING PROCESS:

Start: https://target.com/

Step 1: Fetch homepage
        ├── Extract all links
        │   ├── /about
        │   ├── /products
        │   └── /login
        └── Add to queue

Step 2: Fetch /about
        ├── Extract all links
        │   ├── /team
        │   └── /contact
        └── Add to queue

Step 3: Continue until queue empty

TOOLS:
- Burp Suite Spider (Passive: records as you browse)
- Burp Suite Crawler (Active: autonomous crawling)
- OWASP ZAP Spider
- Katana (CLI, modern)
- gospider (Go-based, fast)

LIMITATIONS:
- Only finds LINKED pages
- JavaScript-rendered content requires headless browser
- Forms behind authentication not reached without creds
```

### Brute Force Directory Discovery

**Finding unlinked content:**

```bash
# Gobuster - Fast, Go-based
gobuster dir -u http://target.com -w /path/to/wordlist.txt

# FFuF - Flexible fuzzer
ffuf -u http://target.com/FUZZ -w /path/to/wordlist.txt

# Feroxbuster - Recursive, fast
feroxbuster -u http://target.com -w /path/to/wordlist.txt

# Common options:
-x php,txt,bak,zip     # File extensions to append
-t 50                  # Threads
-r                     # Follow redirects
--timeout 5            # Request timeout
-o results.txt         # Output file
```

**Understanding responses:**

| Status Code | Meaning | Action |
|-------------|---------|--------|
| **200** | Success | Content exists, examine it |
| **301/302** | Redirect | Follow to see destination |
| **401** | Unauthorized | Exists, needs auth |
| **403** | Forbidden | Exists, blocked |
| **404** | Not found | Doesn't exist (usually) |
| **500** | Server error | Might be exploitable |

### Information Disclosure Files

**Files to always check:**

```
COMMON INFORMATION DISCLOSURE:

CONFIGURATION/SECRETS:
/.env                   # Environment variables, secrets
/config.php             # PHP configuration
/config.json            # JSON configuration
/settings.py            # Django settings
/application.properties # Java/Spring config

SOURCE CODE EXPOSURE:
/.git/                  # Git repository
/.svn/                  # Subversion
/.hg/                   # Mercurial
/backup.zip             # Source backup
/.DS_Store              # macOS directory listing

API DOCUMENTATION:
/swagger.json           # Swagger/OpenAPI spec
/swagger-ui.html        # Swagger UI
/api-docs               # Spring Boot API docs
/graphql                # GraphQL endpoint

DEBUG/ADMIN:
/phpinfo.php            # PHP configuration
/debug/                 # Debug endpoints
/test/                  # Test pages
/admin/                 # Admin panels
/status                 # Health check
/metrics                # Prometheus metrics
/actuator/              # Spring Boot actuator
/actuator/env           # Environment dump

ROBOTS AND SITEMAP:
/robots.txt             # Disallowed paths (goldmine!)
/sitemap.xml            # All indexed pages
```

### JavaScript Analysis

**Finding hidden endpoints in JS:**

```javascript
// Endpoints often hardcoded in JavaScript bundles

// Direct API calls
fetch('/api/v1/users/delete', {...})
axios.get('/internal/admin/stats')
$.ajax({url: '/debug/sql-console'})

// Configuration objects
const API_BASE = 'https://api.target.com/v2';
const endpoints = {
    users: '/api/users',
    admin: '/api/admin',      // Hidden!
    debug: '/api/debug'       // Hidden!
};

// Dynamic path construction
`/api/${version}/users/${userId}/secrets`
```

**Tools for JS analysis:**

```bash
# Extract endpoints from JavaScript
# LinkFinder
python3 linkfinder.py -i https://target.com/app.js -o cli

# Manually: View source, search for:
grep -E "api/|/v[0-9]/|fetch\(|axios\.|\.ajax" app.js

# Extract all from Burp history:
# Target → Engagement tools → Find scripts
```

### Historical Discovery

**Finding removed content:**

```
WAYBACK MACHINE (web.archive.org):

1. Enter target domain
2. Browse historical snapshots
3. Find:
   - Old pages now removed
   - Old API endpoints
   - Configuration files
   - Dev/test resources

TOOLS:
- waybackurls: Extract all URLs from Wayback
  echo "target.com" | waybackurls > urls.txt

- gau (Get All URLs): Multiple sources
  gau target.com > urls.txt

- ParamSpider: Find parameters historically used
```

### API Discovery

**Comprehensive API enumeration:**

```
API DISCOVERY CHECKLIST:

1. DOCUMENTATION
   /docs
   /api/docs
   /swagger.json
   /swagger-ui.html
   /openapi.json
   /api-docs
   /redoc

2. COMMON API PATTERNS
   /api/
   /api/v1/
   /api/v2/
   /rest/
   /graphql
   /query

3. API ENDPOINT FUZZING
   /api/v1/users
   /api/v1/admin
   /api/v1/internal
   /api/v1/debug
   /api/v1/test

4. PARAMETER DISCOVERY
   /api/v1/user?id=1
   /api/v1/user?debug=true
   /api/v1/user?verbose=1
   /api/v1/user?admin=1
```

### Systematic Methodology

**Complete mapping workflow:**

```
WEB APPLICATION MAPPING WORKFLOW:

1. PASSIVE DISCOVERY (No direct interaction)
   ├── Wayback Machine URLs
   ├── Search engine dorking
   ├── Certificate transparency
   └── DNS enumeration

2. ACTIVE BROWSING (Through proxy)
   ├── Click every link
   ├── Submit every form
   ├── Use all features
   └── Proxy records everything

3. AUTOMATED SPIDERING
   ├── Burp Spider/Crawler
   ├── OWASP ZAP Spider
   └── Katana for JS-heavy sites

4. CONTENT DISCOVERY
   ├── robots.txt, sitemap.xml
   ├── Directory brute forcing
   ├── File extension fuzzing
   └── Common path checks

5. JAVASCRIPT ANALYSIS
   ├── Extract all endpoints
   ├── Find hidden routes
   └── Identify API patterns

6. TECHNOLOGY-SPECIFIC
   ├── WordPress: /wp-admin, /wp-includes
   ├── Java: /actuator, /manager
   ├── Node.js: /node_modules exposure
   └── Python: /__pycache__

7. CONSOLIDATE AND PRIORITIZE
   ├── Group by function
   ├── Identify admin/debug pages
   └── Map authentication requirements
```

---

## 3. Guided Practice

### Exercise 1: Manual Discovery

For any target site, check these manually:

| Path | Found? | Contents |
|------|--------|----------|
| /robots.txt | ___ | ___ |
| /sitemap.xml | ___ | ___ |
| /.well-known/ | ___ | ___ |
| /humans.txt | ___ | ___ |

### Exercise 2: Gobuster Basics

Construct gobuster commands for:

1. Basic directory scan:
   ```bash
   gobuster dir -u http://target.com ___
   ```

2. With file extensions:
   ```bash
   gobuster dir -u http://target.com -w wordlist.txt ___
   ```

3. Filtering out 404s explicitly:
   ```bash
   gobuster dir -u http://target.com -w wordlist.txt ___
   ```

### Exercise 3: JavaScript Endpoint Extraction

Find a website with exposed JavaScript. Extract:

1. API endpoints found: ___
2. Hidden paths discovered: ___
3. Configuration URLs: ___

---

## 4. Reflection Check

### Discovery Understanding
1. A spider only found 50 pages, but gobuster found /admin. Why?

2. robots.txt shows "Disallow: /secret-admin/". Is this a security control?

3. You found /api/v1/ but not /api/v2/. How would you find if v2 exists?

### Practical Thinking
1. The target heavily uses JavaScript SPA. Why might a traditional spider fail?

2. You're running gobuster and getting many 403 Forbidden. What does this tell you?

3. Historical URLs from Wayback show /debug/ existed last year. It 404s now. Worth pursuing?

---

## 5. Key Misconceptions

**MYTH: "robots.txt is a security control"**
REALITY: robots.txt tells search engines what not to index. It tells attackers where the interesting stuff is.

**MYTH: "If it's not linked, it can't be found"**
REALITY: Brute forcing, historical archives, and information leakage reveal unlinked content.

**MYTH: "Directory brute forcing is illegal"**
REALITY: It's authorized during penetration tests. For bug bounty, check the program's scope carefully.

**MYTH: "Bigger wordlists are always better"**
REALITY: Bigger = slower + more noise. Start small, expand if needed. Quality over quantity.

**MYTH: "Automated tools find everything"**
REALITY: Manual analysis of JavaScript, API documentation, and error messages often reveals what automation misses.

---

## 6. Completion Criteria

This module is complete when you can:

1. **Apply** multiple discovery techniques systematically
2. **Use** gobuster/ffuf for directory brute forcing
3. **Analyze** JavaScript for hidden endpoints
4. **Check** common information disclosure paths
5. **Build** comprehensive application maps

---

## 7. Further Depth (Optional)

*   **Tool:** Set up and use feroxbuster for recursive scanning
*   **Wordlist:** Explore SecLists for specialized wordlists
*   **Practice:** HackTheBox/TryHackMe web challenges
*   **Automation:** Build a custom recon automation script
