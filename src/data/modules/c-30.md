# Measuring Detection Coverage

## 1. What this module covers
Moving from "It feels secure" to "We have 82% coverage". Quantifying security.

## 2. Why this matters for purple teams
Executives don't understand "Buffer Overflow". They understand "82%".

## 3. Core concepts explained clearly

### Coverage Map (Heatmap)
*   **Rows**: MITRE Tactics (Initial Access, Execution...).
*   **Cells**: Techniques.
*   **Colors**:
    *   **Red**: No logging, No alerting.
    *   **Yellow**: Logs exist, but no Alert.
    *   **Green**: Alert exists and is validated.

### Depth Metric
*   "We cover PowerShell".
*   **Depth 1**: Alerts on `powershell.exe`. (Easy).
*   **Depth 5**: Alerts on Unmanaged PowerShell Reflection. (Hard).

## 4. Validation examples

### Calculating coverage
1.  **Scope**: "Ransomware Techniques" (20 Technqiues).
2.  **Test**: Run all 20.
3.  **Results**:
    *   Blocked: 5.
    *   Detected: 10.
    *   Missed: 5.
4.  **Score**: 75% Visibility. 25% Prevention.

## 5. Common gaps and failures
*   **The "Paper Green"**: Marking a cell Green because "The vendor said they catch it".
    *   *Purple Rule*: Unless you ran it yourself, the cell it Red.

## 6. Key takeaways
*   **Trend**: The number (82%) matters less than the trend (Are we going up or down?).
*   **Gap Analysis**: Use the Red cells to justify budget for new tools.
