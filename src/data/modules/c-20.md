# False Positives and False Negatives

## 1. What this module covers
The two types of failure. Crying Wolf (FP) and Sleeping through the burglary (FN).

## 2. Why this matters for purple teams
Purple Teaming is the ONLY way to measure False Negatives. (You can see False Positives in the console. You can't see what you missed).

## 3. Core concepts explained clearly

### False Positive (FP)
*   Alert fires, but activity is benign.
*   **Cost**: Analyst time wasted. Alert Fatigue.

### False Negative (FN)
*   Attack happens, but Alert does NOT fire.
*   **Cost**: Breach. Data Loss.

### The Trade-off
*   If you tune to 0% False Positives (Strict), you dramatically increase False Negatives.
*   If you tune to 0% False Negatives (Paranoid), you drown in False Positives.
*   **Goal**: Optimal Balance.

## 4. Validation examples

### Measuring FN Rate
1.  **Action**: Run 10 variations of Credential Dumping.
2.  **Result**: 3 Alerts.
3.  **Calculation**: 7 Missed / 10 Total = 70% False Negative Rate.
4.  **Goal**: Tune rules to lower this to < 10%.

## 5. Common gaps and failures
*   **Closing FPs incorrectly**: Analyst sees a weird PowerShell script. Marks it "False Positive" because "It didn't block". Reality: It was a successful hack.
*   **Fear of FPs**: Disabling a rule because it fired once on a Printer. Now you are blind to that attack vector.

## 6. Key takeaways
*   **Feedback**: Feedback from Analyst to Engineer is vital. "This rule is noisy, fix it."
*   **Testing**: Regular Purple Teaming reduces the FN rate.
