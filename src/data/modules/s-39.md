# Cognitive Security: Disinformation

## 1. Orientation

### What this module covers
Attacks are not just code; they can be **narratives**. Cognitive Security deals with Disinformation (Intentional lies) and Misinformation (Unintentional errors). APTs use this to destabilize organizations or nations.

### Learning Objectives
*   Define **MDM** (Mis-, Dis-, Mal-information).
*   Analyze **Botnet Amplification** on social media.
*   Understand **Deepfakes** and synthetic media.

---

## 2. Core Content

### The Trinity (MDM)
1.  **Misinformation:** False, but not malicious (e.g., rumor).
2.  **Disinformation:** False, and malicious (e.g., State propaganda).
3.  **Malinformation:** True, but used maliciously (e.g., Leaking private emails to embarrass).

### The TTPs of Influence
*   **Sock Puppets:** Fake accounts posing as locals.
*   **Astroturfing:** Artificial "grassroots" support.
*   **Narrative Laundering:** Plant story in small blog -> Reference in medium news -> Mainstream news picks it up.

### Corporate Relevance
"Hack and Leak" operations. Attackers steal data, modify it slightly (add fake incriminating emails), and leak it to destroy a company's stock price.

---

## 3. Lab: Bot Spotting

### Scenario
Your company is trending on Twitter with negative hashtag `#EvilCorpScam`.

**Analysis:**
1.  **Creation Date:** 1,000 accounts created this month.
2.  **Activity:** All post at the exact same second.
3.  **Content:** Identical syntax errors.

**Verdict:** Inauthentic Coordinated Behavior (Botnet).

---

## 4. Reflection
1.  How do Deepfakes impact C-Level verification? (Attackers can now mimic the CEO's voice / video on a Zoom call to authorize wire transfers).
2.  What is "Pre-bunking"? (Warning people about a narrative *before* it hits, "inoculating" them against the lie).
