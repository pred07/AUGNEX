# Measuring Detection Effectiveness

## 1. What this module covers
Quality over Quantity. Not "How many alerts?", but "How good are they?"

## 2. Why this matters for purple teams
A SOC that closes 1000 tickets a day might be doing nothing but closing noise.

## 3. Core concepts explained clearly

### True Positive Rate (TPR)
*   Percentage of alerts that were real malicious activity.
*   Goal: > 50%. (Most SOCs are < 5%).

### The "Dwell Time"
*   How long did the attacker persist?
*   Purple Team exercises usually have dwell time of "Minutes". Real breaches have "Months".

## 4. Validation examples

### The "Silent" Test
1.  **Red**: Establish persistence (Scheduled Task) on Server X.
2.  **Wait**: Do nothing for 1 week.
3.  **Check**: Did anyone notice?
    *   If No, your "Effectiveness" for Persistence is 0.

## 5. Common gaps and failures
*   **Gamification**: Analysts closing tickets faster just to improve stats, without actually investigating. "Closing for Stats".

## 6. Key takeaways
*   **Outcome based**: Validating *outcomes* (Did we catch the bad guy?), not *outputs* (How many tickets did we generate?).
