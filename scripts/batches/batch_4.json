[
    {
        "id": "b-16",
        "content": "# Infrastructure as Code (IaC) Fundamentals\n\n## 1. Orientation\n\n### What this module covers\nInfrastructure as Code (IaC) removes the \"ClickOps\" manual process of setting up servers. It treats infrastructure provisioning (Networks, VMs, Load Balancers) as software. This module defines the core principles: Declarative vs. Imperative, Idempotency, and Mutable vs. Immutable infrastructure.\n\n### Learning Objectives\n*   Contrast **Declarative** (Terraform) vs **Imperative** (Ansible/Bash) approaches.\n*   Define **Idempotency** and why it prevents configuration drift.\n*   Explain the security benefits of **Immutable Infrastructure** (Cattle vs. Pets).\n\n---\n\n## 2. Core Content\n\n### Declarative vs. Imperative\n*   **Imperative (How):** \"Connect to server. Install Nginx. Start Service.\" (e.g., Bash script). *Risk:* If you run it twice, it might break.\n*   **Declarative (What):** \"I want a server with Nginx running.\" (e.g., Terraform, K8s). *Benefit:* The tool figures out how to get there. If it's already there, it does nothing.\n\n### Idempotency\nA mathematical property where `f(f(x)) = f(x)`. In DevOps: **Running the same script 100 times should result in the same state as running it once.**\n*   *Bash is rarely idempotent* (e.g., `mkdir folder` fails the second time).\n*   *Ansible/Terraform are designed to be idempotent.*\n\n### Pets vs. Cattle (Immutable)\n*   **Pets:** Servers we name (e.g., \"Zeus\"), patch manually, and nurse back to health when sick. *Drift is inevitable.*\n*   **Cattle:** Servers with IDs (e.g., `i-0a1b2c`), created from a master image. If one is sick, we terminate it and spawn a new one. *Consistency is guaranteed.*\n\n---\n\n## 3. Lab: The Drift Test\n\n### Scenario\nYou have a script `setup.sh`:\n```bash\necho \"dev\" >> /etc/env\napt-get install -y nginx\n```\n\n1.  **Run 1:** Works. `/etc/env` contains \"dev\".\n2.  **Run 2:** `/etc/env` now contains \"dev\\ndev\". **Drift has occurred.**\n3.  **The Ansible Fix:**\n    ```yaml\n    - name: Set Environment\n      lineinfile:\n         path: /etc/env\n         line: \"dev\"\n    ```\n    *Result:* Ansible checks if the line exists first. Run 2 does nothing.\n\n---\n\n## 4. Reflection\n1.  Why is manual \"ClickOps\" in AWS Console considered a security risk? (No audit trail, no rigorous review, easy to make misconfigurations).\n2.  How does IaC enable Disaster Recovery? (You can rebuild your entire datacenter in a new region with one command).\n"
    },
    {
        "id": "b-17",
        "content": "# Terraform: Provisioning Infrastructure\n\n## 1. Orientation\n\n### What this module covers\nTerraform is the industry standard for **Provisioning** infrastructure (Hardware). It uses HCL (HashiCorp Configuration Language). We will learn how to define resources, manage state, and use providers.\n\n### Learning Objectives\n*   Write basic HCL syntax (`resource`, `provider`, `variable`).\n*   Understand the **Terraform State File** (`.tfstate`) and its sensitivity.\n*   Execute the Workflow: `init` -> `plan` -> `apply`.\n\n---\n\n## 2. Core Content\n\n### The Workflow\n1.  **Write:** Define infrastructure in `main.tf`.\n2.  **Init:** `terraform init` downloads necessary plugins (e.g., AWS provider).\n3.  **Plan:** `terraform plan` compares your code to the current state. It tells you *exactly* what it will create/destroy.\n4.  **Apply:** `terraform apply` executes the changes.\n\n### The State File (`terraform.tfstate`)\nThis JSON file maps your code to real-world resources. \n*   **CRITICAL SECURITY RISK:** The state file often contains PLAINTEXT SECRETS (DB passwords) even if you used variables. \n*   **Protection:** Store state remotely (S3 Backend) with Encryption (KMS) and Access Control.\n\n### HCL Syntax Example\n```hcl\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n\nresource \"aws_s3_bucket\" \"logs\" {\n  bucket = \"my-secure-logs\"\n  acl    = \"private\"\n\n  versioning {\n    enabled = true\n  }\n}\n```\n\n---\n\n## 3. Lab: Reading a Plan\n\n### Task\nYou run `terraform plan` and see:\n```diff\n  # aws_security_group.allow_ssh will be updated in-place\n  ~ ingress {\n      cidr_blocks = [\n        - \"10.0.0.0/8\",\n        + \"0.0.0.0/0\",\n      ]\n    }\n```\n**Analysis:** usage of `~` means modification. The `+` indicates adding `0.0.0.0/0` (Anywhere) to SSH. \n**Action:** ABORT. Do not apply. Ideally, a Policy-as-Code tool should block this automatically.\n\n---\n\n## 4. Reflection\n1.  Why should you never commit `.tfstate` to Git? (It exposes secrets and locks the state to your local machine).\n2.  What is `terraform destroy`? (The nuclear option. It deletes everything defined in the configuration).\n"
    },
    {
        "id": "b-18",
        "content": "# Ansible: Configuration Management\n\n## 1. Orientation\n\n### What this module covers\nWhile Terraform builds the *Server* (Hardware), Ansible configures the *Software* inside it. Ansible is **Agentless** (uses SSH) and uses YAML for its Playbooks.\n\n### Learning Objectives\n*   Understand the **Inventory** file.\n*   Write a **Playbook** with multiple Tasks.\n*   Use **Modules** (`apt`, `service`, `copy`) instead of shell commands.\n\n---\n\n## 2. Core Content\n\n### inventory.ini\nA list of targets.\n```ini\n[webservers]\n192.168.1.10\n192.168.1.11\n\n[dbservers]\n192.168.1.50\n```\n\n### The Playbook (YAML)\n```yaml\n- name: Secure Web Server\n  hosts: webservers\n  become: yes\n\n  tasks:\n    - name: Install Apache\n      apt: \n        name: apache2 \n        state: present\n\n    - name: Disable Root Login\n      lineinfile:\n        path: /etc/ssh/sshd_config\n        regexp: '^PermitRootLogin'\n        line: 'PermitRootLogin no'\n      notify: Restart SSH\n\n  handlers:\n    - name: Restart SSH\n      service:\n        name: sshd\n        state: restarted\n```\n\n### Agentless Security\nAnsible uses standard SSH. You don't need to install a proprietary agent on every server. \n*   **Auth:** Uses Keys. You need the private key on the Control Node.\n\n---\n\n## 3. Lab: Idempotency Check\n\n### Scenario\nYou run the playbook above. \n*   **Result 1:** `changed=2` (Installed Apache, Disabled Root).\n*   **Result 2 (Run again):** `changed=0`. \n\n**Why?** The `apt` module checked if apache was installed. It saw \"yes\", so it did nothing. This is safe automation.\n\n---\n\n## 4. Reflection\n1.  Why is `become: yes` dangerous if not audited? (It grants Root privileges for the task. Use Least Privilege where possible).\n2.  How is Ansible different from a Bash script loop? (Error handling, reporting, and idempotency are built-in).\n"
    },
    {
        "id": "b-19",
        "content": "# Secrets Management in IaC (Vault)\n\n## 1. Orientation\n\n### What this module covers\nHardcoding passwords in code (GitHub) is the #1 cause of cloud breaches. This module covers strategies to externalize secrets using tools like HashiCorp Vault, AWS Secrets Manager, and environment variables.\n\n### Learning Objectives\n*   Identify the risk of \"Secret Sprawl.\"\n*   Implement **Environment Variables** for basic protection.\n*   Understand the workflow of **HashiCorp Vault** (Dynamic Secrets).\n\n---\n\n## 2. Core Content\n\n### The Problem: Hardcoded Credentials\n```python\n# BAD\ndb_pass = \"SuperSecret123\" \nconn = connect(db_pass)\n```\nIf this file is pushed to Git, the password is compromised forever (even if you delete it in the next commit, it's in history).\n\n### Level 1: Environment Variables\n```python\n# BETTER\nimport os\ndb_pass = os.getenv('DB_PASSWORD')\n```\n*   *Pros:* Secret is not in code.\n*   *Cons:* Secret is visible in `ps aux` or logs if not careful.\n\n### Level 2: Secrets Management Platform (Vault)\nCentralized storage. The App authenticates to Vault (via Token/IAM) and asks for the secret.\n*   **Dynamic Secrets:** Vault can create a *temporary* database user for the app that expires in 1 hour. Even if stolen, the credence is short-lived.\n\n### Git Scanning\nUse tools like `trufflehog` or `gitleaks` in your CI/CD pipeline to block commits that look like keys.\n\n---\n\n## 3. Lab: Vault Workflow\n\n### Workflow\n1.  **Admin:** Writes secret `foo=bar` to Vault path `secret/app`.\n2.  **App:** Authenticates to Vault.\n3.  **App:** Requests `secret/app`.\n4.  **Vault:** Returns `{foo: bar}`.\n5.  **App:** Uses `bar` to connect.\n\n*   **Result:** The secret only exists in Memory of the App and Storage of Vault. It never touches the disk or Git.\n\n---\n\n## 4. Reflection\n1.  What is the \"Secret Zero\" problem? (You need a secret [token] to authenticate to Vault to get secrets. How do you protect the first token?).\n2.  Why are Dynamic Secrets superior to Static Passwords? (They enforce rotation and limits the blast radius of a leak automatically).\n"
    },
    {
        "id": "b-20",
        "content": "# Policy as Code (OPA / Sentinel)\n\n## 1. Orientation\n\n### What this module covers\nManual code reviews cannot scale to thousands of deployments a day. **Policy as Code** (PaC) automates compliance/security checks. We define rules (e.g., \"No S3 buckets shall be public\") and the CI/CD pipeline blocks any code that violates them.\n\n### Learning Objectives\n*   Understand the concept of \"Compliance as Code.\"\n*   Write a basic **OPA (Open Policy Agent)** Rego rule.\n*   Integrate Policy checks into the Terraform pipeline.\n\n---\n\n## 2. Core Content\n\n### The Shift Left\nInstead of a security team auditing AWS *after* deployment (Reactive), the pipeline checks the Terraform code *before* deployment (Proactive).\n\n### Open Policy Agent (OPA)\nThe industry standard for PaC. It uses a language called **Rego**.\n\n### Example: Blocking Public IPs\n**Terraform Input (JSON):**\n```json\n{\n  \"resource\": {\n    \"aws_instance\": {\n      \"web\": { \"associate_public_ip_address\": true }\n    }\n  }\n}\n```\n\n**Rego Policy:**\n```rego\ndeny[msg] {\n  resource := input.resource.aws_instance[_]\n  resource.associate_public_ip_address == true\n  msg = \"Public IPs are forbidden for EC2 instances.\"\n}\n```\n*   **Outcome:** If the input matches the logic, the deployment is DENIED.\n\n---\n\n## 3. Lab: The Gatekeeper\n\n### Scenario\nDeveloper tries to deploy an S3 bucket with `acl = \"public-read\"`.\n\n1.  **Pipeline Running:**\n    *   Step 1: `terraform plan -out=tfplan`\n    *   Step 2: `terraform show -json tfplan > tfplan.json`\n    *   Step 3: `opa eval -i tfplan.json -d policies/s3.rego \"data.main.deny\"`\n\n2.  **Policy Result:**\n    *   Rule: `deny if acl != private`.\n    *   Output: `[\"S3 bucket must be private\"]`.\n\n3.  **Action:** Pipeline Fails. Deployment stopped.\n\n---\n\n## 4. Reflection\n1.  How does this help with Audits (SOC2/ISO)? (Your policy code *is* your documentation. You prove that non-compliant infrastructure *cannot* exist).\n2.  What is the difference between specific static analysis (tfsec) and generic PaC (OPA)? (OPA is a general purpose engine that can audit K8s, Terraform, Envoy, and Linux, providing a unified language for policy).\n"
    }
]