[
    {
        "id": "s-21",
        "content": "# Attribution: The Art of \"Who done it?\"\n\n## 1. Orientation\n\n### What this module covers\nAttribution is the process of identifying the actor behind an attack. It is the most politically charged and technically difficult part of CTI. This module covers the **Levels of Attribution**, **False Flags**, and why \"Who Analysis\" (naming the actor) is often less important than \"How Analysis\" (stopping the TTP).\n\n### Learning Objectives\n*   Understand the **levels of confidence** in attribution.\n*   Analyze **technical artifacts** vs **strategic context**.\n*   Identify **False Flag** operations designed to deceive analysts.\n\n---\n\n## 2. Core Content\n\n### Can you *really* know?\nAn IP address only tells you which computer sent the packet, not who was sitting in the chair. Attribution is almost always probabilistic, not deterministic.\n\n### The Hierarchy of Attribution Indicators\n1.  **Low Confidence:** IP Addresses (Proxies), Domain Names (Registrars).\n2.  **Medium Confidence:** Toolsets (Malware families), Infrastructure overlap (Reused SSL certs).\n3.  **High Confidence:** Use of Non-Public Exploits (0-days), Language artifacts in code, Time zone analysis, Strategic alignment (Geopolitics).\n\n### False Flags\nSophisticated actors (APTs) *deliberately* plant evidence to frame others.\n*   *Example:* The \"Olympic Destroyer\" malware contained code fragments from North Korean malware (Lazarus) but was actually written by Russia (Sandworm).\n\n### The \"Attribution Paradox\"\n*   **Strategic Level:** Attribution is crucial. (A nation-state needs to know who to sanction).\n*   **Tactical Level:** Attribution is irrelevant. ('I don't care if it's Russia or China; I just need to block their lateral movement').\n\n---\n\n## 3. Lab: The Evidence Board\n\n### Scenario\nYou are analyzing a breach at a Defense Contractor. You find:\n\n1.  **Time:** Attacks occurred between 08:00 and 17:00 Beijing Time.\n2.  **Tool:** A custom RAT seen only in APT10 campaigns.\n3.  **String:** A PDB path in the binary: `C:\\Users\\Wang\\Project\\Dev...`\n\n**Assessment:**\n*   The Timezone matches China.\n*   The Tool matches APT10.\n*   The String implies a Chinese name.\n\n**Verdict:** High Confidence: APT10.\n\n**Devilish Twist:**\nWhat if the attacker *compiled the binary on a machine with the timezone set to Beijing* to trick you? This is why we need **multiple independent sources** of evidence.\n\n---\n\n## 4. Reflection\n1.  Why is the PDB path `C:\\Users\\Wang\\...` suspicious as a \"Too Good To Be True\" indicator? (Professional malware authors rarely leave their home directory paths in final builds unless they are sloppy or it's a false flag).\n2.  Why is \"Infrastructure Overlap\" (e.g., reusing an SSH key) a strong indicator? ( Attackers are lazy. Setting up new servers takes time. Reusing a key links two separate campaigns irrevocably).\n"
    },
    {
        "id": "s-22",
        "content": "# The Cyber Kill Chain\n\n## 1. Orientation\n\n### What this module covers\nDeveloped by Lockheed Martin, the Cyber Kill Chain models the seven steps an adversary *must* complete to achieve their objective. It is a linear defense model: **Break any link in the chain, and you stop the attack.**\n\n### Learning Objectives\n*   Memorize the **7 Phases** of the Kill Chain.\n*   Map defensive controls to specific phases.\n*   Understand the limitations of the model (it assumes a perimeter).\n\n---\n\n## 2. Core Content\n\n### The 7 Phases\n\n1.  **Reconnaissance:** Researching the target (Harvesting emails, LinkedIn).\n    *   *Defense:* Detection is hard. Alerts on \"Dark Web\" mentions.\n2.  **Weaponization:** Coupling an exploit with a deliverable payload (Creating the PDF).\n    *   *Defense:* N/A (Happens on attacker's machine).\n3.  **Delivery:** Transmitting the weapon (Email Phishing, USB).\n    *   *Defense:* Email Gateway, Spam filters.\n4.  **Exploitation:** Triggering the code (Vulnerability triggered).\n    *   *Defense:* Patching, DEP/ASLR, EDR.\n5.  **Installation:** Installing the backdoor (Persistence).\n    *   *Defense:* EDR, File Integrity Monitoring.\n6.  **Command & Control (C2):** Communicating home.\n    *   *Defense:* Firewall, DNS Filtering, Proxy logs.\n7.  **Actions on Objectives:** Stealing data, Encrypting files.\n    *   *Defense:* DLP, Network Segmentation, Backups.\n\n### \"Left of Boom\"\nBoom = The Compromise (Exploitation). Moving \"Left of Boom\" means detecting them at Recon/Delivery. Moving \"Right of Boom\" means Incident Response.\n\n---\n\n## 3. Lab: Breaking the Chain\n\n### Scenario\nAn attacker sends a Phishing Email with a malicious Excel file. The user opens it. The Macro runs PowerShell. PowerShell downloads an EXE. The EXE encrypts the drive.\n\n**Map the Interventions:**\n1.  **Recon:** Attacker found user's email on website. (Defense: Remove email from public site).\n2.  **Delivery:** Email arrives. (Defense: DMARC/SPF/DKIM check).\n3.  **Exploitation:** Macro runs. (Defense: GPO \"Block Macros from Internet\").\n4.  **C2:** Download EXE. (Defense: DNS Filter blocks evil.com).\n5.  **Actions:** Encrypts drive. (Defense: Controlled Folder Access / Offline Backups).\n\nIf *any* of these succeed, the attack fails.\n\n---\n\n## 4. Reflection\n1.  Why is the Kill Chain criticized for being \"Perimeter Focused\"? (It assumes the attacker is on the outside. It doesn't model Insider Threats well).\n2.  Which phase allows the defender to detect the attacker *before* the malware lands? (Delivery - via email scanning).\n"
    },
    {
        "id": "s-23",
        "content": "# The Diamond Model of Intrusion Analysis\n\n## 1. Orientation\n\n### What this module covers\nWhile the Kill Chain focuses on *process*, the Diamond Model focuses on *relationships*. Every intrusion event has four core features: **Adversary, Victim, Infrastructure, and Capability**. Mapping these points helps cluster activity into campaigns.\n\n### Learning Objectives\n*   Draw the Diamond Model.\n*   Pivot between vertices to discover new intel.\n*   Group events to identify a Campaign.\n\n---\n\n## 2. Core Content\n\n### The Vertices\n```\n      Adversary\n      /       \\\nInfrastructure Capability\n      \\       /\n       Victim\n```\n\n1.  **Adversary:** Who is attacking? (Email address, Handle).\n2.  **Victim:** Who is being attacked? (Network, Person, Asset).\n3.  **Infrastructure:** What are they using to connect? (IP, Domain, Email Server).\n4.  **Capability:** What tools are they using? (Malware, Exploit, TTP).\n\n### The Pivot\nThe power of the model is moving from one known point to an unknown point.\n*   *Example:* You know the **Capability** (A specific malware hash). You analyze it and find a C2 **Infrastructure** (IP). You query Passive DNS for that IP and find a new **Adversary** email registered to it.\n\n### Meta-Features\n*   **Timestamp:** When did it happen?\n*   **Phase:** Where in the Kill Chain?\n*   **Result:** Success/Failure?\n\n---\n\n## 3. Lab: Diamond Clustering\n\n### Scenario\nYou have 3 incidents.\n\n*   **Incident A:** Victim=Finance, Infra=1.2.3.4, Cap=DarkComet.\n*   **Incident B:** Victim=HR, Infra=1.2.3.4, Cap=DarkComet.\n*   **Incident C:** Victim=Engineering, Infra=5.6.7.8, Cap=CobaltStrike.\n\n**Analysis:**\n*   Incidents A and B share **Infrastructure** and **Capabilities**. They are likely the same **Adversary** (Campaign 1).\n*   Incident C shares nothing. It is likely a different **Adversary** (Campaign 2).\n\n---\n\n## 4. Reflection\n1.  How does the Diamond Model help in attribution? (It mathematically links victims and capabilities to infrastructure, which is often the bridge to the adversary's identity).\n2.  Can you have the Diamond Model without an Adversary? (Yes. Most of the time the \"Adversary\" top vertex is unknown/blank at the start of an investigation).\n"
    },
    {
        "id": "s-24",
        "content": "# MITRE ATT&CK Framework\n\n## 1. Orientation\n\n### What this module covers\nMITRE ATT&CK (Adversarial Tactics, Techniques, and Common Knowledge) is the periodic table of hacker behavior. Unlike the Kill Chain (7 steps), ATT&CK allows for non-linear, granular descriptions of behavior (e.g., \"T1059.001: PowerShell\"). It is the global standard for CTI categorization.\n\n### Learning Objectives\n*   Distinguish between **Tactics** (Goal) and **Techniques** (Method).\n*   Navigate the ATT&CK Matrix.\n*   Use ATT&CK Navigator to visualize coverage.\n\n---\n\n## 2. Core Content\n\n### Tactics vs Techniques\n*   **Tactic (Why):** The adversary's tactical goal. (e.g., \"Credential Access\").\n*   **Technique (How):** The specific way they achieve it. (e.g., \"OS Credential Dumping: LSASS Memory\").\n*   **Procedures (Detailed How):** The exact tool/command used. (e.g., \"Mimikatz sekurlsa::logonpasswords\").\n\n### The Matrix\n14 Tactics (Columns). Hundreds of Techniques (Rows).\n1.  Reconnaissance\n2.  Resource Development\n3.  Initial Access\n4.  Execution\n5.  Persistence\n6.  Privilege Escalation\n7.  Defense Evasion\n8.  Credential Access\n9.  Discovery\n10. Lateral Movement\n11. Collection\n12. Command and Control\n13. Exfiltration\n14. Impact\n\n### Using it for Defense\nDo not try to \"Block T1059\". You can't block all Command and Scripting Interpreters. Instead, map your detection gaps. \"We have good coverage for *Exfiltration* but zero coverage for *Discovery*.\"\n\n---\n\n## 3. Lab: Mapping to ATT&CK\n\n### Task\nMap the following behaviors to IDs:\n\n1.  Attacker sends a Spearphishing Link. -> **T1566.002** (Phishing: Spearphishing Link).\n2.  Attacker adds a registry key to auto-start. -> **T1547.001** (Boot or Logon Autostart Execution: Registry Run Keys).\n3.  Attacker deletes Volume Shadow Copies. -> **T1490** (Inhibit System Recovery).\n\n*Reference: `attack.mitre.org`*\n\n---\n\n## 4. Reflection\n1.  Why is ATT&CK better than the Kill Chain for Red Teaming? (It describes *what to do* in detail, rather than just \"Exploit\").\n2.  What is a \"Sub-technique\"? (e.g., Phishing is the technique. Spearphishing Attachment is the Sub-technique .001. It adds granularity).\n"
    },
    {
        "id": "s-25",
        "content": "# Campaign Analysis & Tracking\n\n## 1. Orientation\n\n### What this module covers\nA single intrusion is an incident. A series of intrusions by the same actor with the same goal is a **Campaign**. This module covers the methodology of tracking campaigns over time using naming conventions and trend analysis.\n\n### Learning Objectives\n*   Define a Campaign based on shared TTPs.\n*   Adopt a consistent Naming Convention.\n*   Create a Strategic Threat Profile.\n\n---\n\n## 2. Core Content\n\n### Defining a Campaign\nYou need a cluster of evidence (Diamond Model). \n*   *Hypothesis:* \"All attacks using the 'BlueBanana' malware against banks in July are related.\"\n*   *Validation:* Do they assume the same C2 structure? Do they recycle code?\n\n### Naming Conventions\nEveryone names things differently (CrowdStrike: FANCY BEAR, Mandiant: APT28, Microsoft: Strontium). \n*   **Best Practice:** Use internal code names until you can confidently map to a public group. Call it \"UNC123\" (Uncategorized 123) or \"Activity Group A\". \n*   *Why?* If you incorrectly call it \"APT28\", executives will assume it's Russia. If it turns out to be a teenager, you lose credibility.\n\n### Tracking Trends\nCTI is not just about today. It's about the delta.\n*   \"Last year, Group A used Phishing. This year, they are using VPN Vulnerabilities.\"\n*   \"Their dwell time decreased from 40 days to 4 days.\"\n*   **This informs investment:** \"We need to stop buying Email filters and start patching VPNs.\"\n\n---\n\n## 3. Lab: The Merger\n\n### Scenario\nYou have two internal activity groups:\n*   **Group A:** Targets HR. Uses \"MacroBackdoor\". IPs: 1.1.1.1.\n*   **Group B:** Targets Finance. Uses \"MacroBackdoor v2\". IPs: 1.1.1.2.\n\n**New Evidence:**\nMalware analysis shows \"MacroBackdoor v2\" contains a hardcoded fallback IP of `1.1.1.1`.\n\n**Decision:**\nMerge Group A and Group B. This is one campaign evolving its toolset.\n\n---\n\n## 4. Reflection\n1.  Why do vendors use different names for the same actor? (Marketing/Branding. \"Pandas\" vs \"Bears\" vs \"Kittens\" creates brand recognition).\n2.  What is the risk of merging groups too early? (You might blend two distinct actors into one profile, confusing your analysis of their motives).\n"
    }
]